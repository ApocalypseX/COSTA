{
    "env_name": "ant-goal-safe",
    "seed": 0,
    "num_tasks": 3,
    "max_buffer_size": 2000000,
    "goal_radius": 3,
    "state_dim": 29,
    "action_dim": 8,
    "hidden_dim": [256,256,256],
    "batch_size": 1024,
    "sequence_batch_size": 3,
    "use_sequence_batch": false,
    "eval_size": 10000,
    "data_path": "offline_data/ant-goal-safe_2/offline_buffer.npz",
    "device": "cuda",
    "vae_path": "run/ant-goal-safe_2/vae/vae.pt",
    "actor_lr": 1e-4,
    "critic_lr": 3e-4,
    "critic_c_lr":3e-4,
    "gamma": 0.99,
    "tau": 0.005,
    "alpha": 0.2,
    "target_entropy": null,
    "auto_alpha": true,
    "alpha_lr": 1e-4,
    "cql_weight": 5.0,
    "cpq_weight": 1.0,
    "kl_threshold": 14.0,
    "temperature": 1.0,
    "max_q_backup": false,
    "deterministic_backup": true,
    "with_lagrange": false,
    "use_state_augmentation": false,
    "lagrange_threshold": 10.0,
    "cql_alpha_lr": 3e-4,
    "use_vae": true,
    "train_cpq_alpha": true,
    "use_safety_lagrange": false,
    "safety_lagrange_pid": false,
    "use_conservative_reward_loss": true,
    "use_conservative_cost_loss": true,
    "warm_up_epoch": 15,
    "num_repeat_actions": 10,
    "safety_threshold": 25.0,
    "cpq_alpha_lr": 3e-4,
    "policy_train": "sac",
    "epoch": 100,
    "step_per_epoch": 1000,
    "eval_episodes": 10,
    "max_cost_value": 20.0,
    "context_sequence_num": 1,
    "exp_trj_num": 10,
    "rnd_trj_num": 0,
    "bootstrap_trj_num":0,
    "iid_min_reward": 600,
    "lgr_lower_bound": 0.2,
    "lgr_upper_bound": 10.0,
    "lagrange_params":{
        "cost_limit": 25.0,
        "lagrangian_multiplier_init": 1.0,
        "lambda_lr": 0.001,
        "lambda_optimizer": "Adam",
        "lagrangian_upper_bound": 1e4
    },
    "env_params": {
        "n_tasks": 3,
        "max_episode_steps": 300
    },
    "meta_params": {
        "encoder_type": "mlp_attn",
        "focal_path": "focal_context_encoder/20230815195405/model/encoder100.pt",
        "corro_path": "corro_context_encoder/20230815200920/model/encoder100.pt",
        "mlp_attn_path": "20230815200331/model/encoder100.pt",
        "wo_cl_path": "context_encoder_wo_cl/20230926175448/model/encoder100.pt"
    },
    "util_params": {
        "use_gpu": 1
    },
    "vae_params": {
        "max_buffer_size": 2000000,
        "goal_radius": 3,
        "state_dim": 29,
        "action_dim": 8,
        "latent_dim": 16,
        "max_action": 1.0,
        "hidden_unit": 128,
        "beta": 0.01,
        "epoch_num": 100,
        "batch_size": 512,
        "learning_rate": 1e-3,
        "eval_size": 10000,
        "seed": 0,
        "path": "run",
        "data_path": "offline_data"
    },
    "discriminator_params": {
        "max_buffer_size": 2000000,
        "goal_radius": 3,
        "state_dim": 29,
        "action_dim": 8,
        "hidden_dims": [128,64,32,16],
        "weight_decay": [2.5e-5, 5e-5, 7.5e-5, 7.5e-5, 1e-4],
        "max_action": 1.0,
        "hidden_unit": 128,
        "beta": 0.01,
        "epoch_num": 20,
        "batch_size": 512,
        "train_ratio": 0.8,
        "learning_rate": 5e-4,
        "dropout_rate": 0,
        "output_dim": 1,
        "eval_size": 10000,
        "seed": 0,
        "path": "run",
        "data_path": "offline_data"
    },
    "context_params": {
        "env_name": "ant-goal-safe",
        "ep_length": 300,
        "max_buffer_size": 2000000,
        "goal_radius": 3,
        "num_tasks": 3,
        "state_dim": 29,
        "action_dim": 8,
        "hidden_dims": [128,64,32,16],
        "encode_dim": 16,
        "encoder_hidden_dim":128,
        "encoder_hidden_layers": [128,64,32],
        "decoder_hidden_layers": [128,64,32,16],
        "num_epochs": 100,
        "train_steps_per_epoch":100,
        "batch_size": 512,
        "train_ratio": 0.8,
        "contrastive_weight": 0.01,
        "decoder_weight": 1.0,
        "learning_rate": 1e-4,
        "decay_rate": 0.9,
        "decay_step": 2000,
        "dropout_rate": 0,
        "output_dim": 1,
        "eval_size": 10000,
        "seed": 0,
        "meta_batch_size": 8,
        "context_sequence_num": 1,
        "reward_std": 0.1,
        "negative_num": 1,
        "save_interval": 10,
        "log_interval": 1,
        "log_vis_interval": 10,
        "path": "run",
        "pretrained_encoder": null
    }
}
